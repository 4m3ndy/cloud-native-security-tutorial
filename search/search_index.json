{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This KubeCon EU 2020 tutorial will get you off the ground with Kubernetes security basics, using live demos and examples to work through yourself. We\u2019ll start with possible attack vectors, to help you map out the threat model that applies to your cluster, so you can figure out where you need to focus your efforts for security. We\u2019ll show you how to compromise a deployment with a pod running with a known vulnerability. Once you\u2019ve had the attacker\u2019s eye-view, we\u2019ll walk you through the most important techniques and open source tools to prevent compromise. Sign up now!","title":"Overview"},{"location":"compromise/","text":"A compromised pod \u00b6 In this section we deliberately introduce a container image with a known vulnerability so that you can enjoy the experience of exploiting it! Run a server vulnerable to Shellshock \u00b6 We're using a container with Shellshock , a vulnerability in bash that allows an attacker to remotely execute commands. To make it really easy, we're providing a Helm chart that installs the vulnerable deployment. DO NOT RUN THIS IN A REAL CLUSTER! helm install shellshockable https://lizrice.github.io/shellshockable/shellshockable-0.1.0.tgz This will run a deployment with a single pod. It might take a few seconds to pull the image so check that it's up and running (your pod name will be different): $ kubectl get pods NAME READY STATUS RESTARTS AGE shellshockable-d5b7d44b4-9rpzd 1/1 Running 0 70s In a separate terminal window, run port forwarding so we can make curl requests to this pod. This maps localhost port 8081 to the pod's port 80. kubectl port-forward $(kubectl get pods -l app.kubernetes.io/name=shellshockable -o name) 8081:80 You can now use curl (or a browser) to view the web service running on this pod. For example, if you open localhost:8081 in your web browser, you'll see the Apache2 default welcome page. There is also a script that will return the words \"Regular, expected output\" at the address localhost:8081/cgi-bin/shockme.cgi . If you look at the source for the script you'll see that it's executed using bash . This container is using a compromised version of bash with the Shellshock vulnerability, that an attacker can exploit to execute commands. First let's see the regular text is returned if we use curl to make the HTTPS request: $ curl localhost:8081/cgi-bin/shockme.cgi Regular, expected output You've seen the web server return content as expected. Now it's time to act like an attacker and exploit the Shellshock vulnerability. Exploit the vulnerability \u00b6 You can exploit Shellshock by passing a User-Agent header on the curl request with the -A parameter. This gets expanded as an environment variable by bash , and because of the Shellshock vulnerability, it can be used to execute arbitrary commands. For example curl -A \"() { :; }; echo \\\"Content-type: text/plain\\\"; echo; /bin/cat /etc/passwd\" localhost:8081/cgi-bin/shockme.cgi Instead of running the CGI script as normal, this reponds to the HTTP request with the contents of /etc/passwd ! Preventing this attack \u00b6 The safest way to prevent this attack is to ensure the vulnerable version of bash isn't included in the container image before it's deployed. This is done with container image scanning . Image scanning can only detect known, published vulnerabilities. You can also limit the likely damage of as-yet-unknown compromises by configuring containers to run more securely and using policies to enforce safer configuration. Optional questions and exercises \u00b6 If you have the time and interest, here are some additional things you might like to think about. Try running some other commands as if you were an attacker! For example, you could find out what environment variables are set see what user ID you're running as explore the contents of the filesystem to see what is available Where does this /etc/passwd file come from - the host or the container? What would happen if you mounted files from the host into this container? Take a look at the Dockerfile that builds the container image used in this example. It deliberately installed an old, vulnerable version of bash . Try running a deployment with an up-to-date version of apache2 without the vulnerability, and check that you can't exploit it in the same way.","title":"Compromise a pod!"},{"location":"compromise/#a-compromised-pod","text":"In this section we deliberately introduce a container image with a known vulnerability so that you can enjoy the experience of exploiting it!","title":"A compromised pod"},{"location":"compromise/#run-a-server-vulnerable-to-shellshock","text":"We're using a container with Shellshock , a vulnerability in bash that allows an attacker to remotely execute commands. To make it really easy, we're providing a Helm chart that installs the vulnerable deployment. DO NOT RUN THIS IN A REAL CLUSTER! helm install shellshockable https://lizrice.github.io/shellshockable/shellshockable-0.1.0.tgz This will run a deployment with a single pod. It might take a few seconds to pull the image so check that it's up and running (your pod name will be different): $ kubectl get pods NAME READY STATUS RESTARTS AGE shellshockable-d5b7d44b4-9rpzd 1/1 Running 0 70s In a separate terminal window, run port forwarding so we can make curl requests to this pod. This maps localhost port 8081 to the pod's port 80. kubectl port-forward $(kubectl get pods -l app.kubernetes.io/name=shellshockable -o name) 8081:80 You can now use curl (or a browser) to view the web service running on this pod. For example, if you open localhost:8081 in your web browser, you'll see the Apache2 default welcome page. There is also a script that will return the words \"Regular, expected output\" at the address localhost:8081/cgi-bin/shockme.cgi . If you look at the source for the script you'll see that it's executed using bash . This container is using a compromised version of bash with the Shellshock vulnerability, that an attacker can exploit to execute commands. First let's see the regular text is returned if we use curl to make the HTTPS request: $ curl localhost:8081/cgi-bin/shockme.cgi Regular, expected output You've seen the web server return content as expected. Now it's time to act like an attacker and exploit the Shellshock vulnerability.","title":"Run a server vulnerable to Shellshock"},{"location":"compromise/#exploit-the-vulnerability","text":"You can exploit Shellshock by passing a User-Agent header on the curl request with the -A parameter. This gets expanded as an environment variable by bash , and because of the Shellshock vulnerability, it can be used to execute arbitrary commands. For example curl -A \"() { :; }; echo \\\"Content-type: text/plain\\\"; echo; /bin/cat /etc/passwd\" localhost:8081/cgi-bin/shockme.cgi Instead of running the CGI script as normal, this reponds to the HTTP request with the contents of /etc/passwd !","title":"Exploit the vulnerability"},{"location":"compromise/#preventing-this-attack","text":"The safest way to prevent this attack is to ensure the vulnerable version of bash isn't included in the container image before it's deployed. This is done with container image scanning . Image scanning can only detect known, published vulnerabilities. You can also limit the likely damage of as-yet-unknown compromises by configuring containers to run more securely and using policies to enforce safer configuration.","title":"Preventing this attack"},{"location":"compromise/#optional-questions-and-exercises","text":"If you have the time and interest, here are some additional things you might like to think about. Try running some other commands as if you were an attacker! For example, you could find out what environment variables are set see what user ID you're running as explore the contents of the filesystem to see what is available Where does this /etc/passwd file come from - the host or the container? What would happen if you mounted files from the host into this container? Take a look at the Dockerfile that builds the container image used in this example. It deliberately installed an old, vulnerable version of bash . Try running a deployment with an up-to-date version of apache2 without the vulnerability, and check that you can't exploit it in the same way.","title":"Optional questions and exercises"},{"location":"gitops/","text":"GitOps \u00b6 Concept \u00b6 Using Flux \u00b6 Using ArgoCD \u00b6","title":"GitOps"},{"location":"gitops/#gitops","text":"","title":"GitOps"},{"location":"gitops/#concept","text":"","title":"Concept"},{"location":"gitops/#using-flux","text":"","title":"Using Flux"},{"location":"gitops/#using-argocd","text":"","title":"Using ArgoCD"},{"location":"introduction/","text":"Introduction \u00b6 TODO! document the attack vectors We\u2019ll start with possible attack vectors, to help you map out the threat model that applies to your cluster, so you can figure out where you need to focus your efforts for security. We\u2019ll show you how to compromise a deployment with a pod running with a known vulnerability. Once you\u2019ve had the attacker\u2019s eye-view, we\u2019ll walk you through the most important techniques and open source tools to prevent compromise. Scanning container images for vulnerabilities Configuring container images with security in mind, and checking them with policies Checking your Kubernetes configuration Enhancing security using GitOps Create a Kubernetes cluster \u00b6 To follow along with the practical examples in this tutorial you'll need a Kubernetes cluster that you can experiment with. Since at times you will be deploying insecure code, please don't use your production cluster! You can run a cluster locally on your laptop, for example using Kind - Kubernetes IN Docker . We'll also be using Helm to run software on the Kind cluster. Install kind \u00b6 You can skip this step if you already have an up-to-date installation of kind . On MacOS using Homebrew: brew install kind On MacOS / Linux: curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.8.1/kind-$(uname)-amd64 chmod +x ./kind mv ./kind /some-dir-in-your-PATH/kind On Windows using Chocolatey: choco install kind For more details see the kind quickstart guide . Create the kind cluster \u00b6 kind create cluster Once it's up and running, check that you can see the node is up and running: kubectl get nodes This should show something like this: NAME STATUS ROLES AGE VERSION kind-control-plane Ready master 78m v1.18.2 Great! You have a Kubernetes cluster running locally that you can experiment with. Install Helm \u00b6 If you don't already have Helm on your laptop, you'll want to install that too. Find full instructions in the Helm documentation or here is a quick guide: On MacOS using Homebrew: brew install helm On MacOS / Linux: curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 chmod +x get_helm.sh ./get_helm.sh On Windows using Chocolatey: choco install kubernetes-helm If you have a fresh Kind installation there won't be any Helm charts installed yet, so a helm ls will return an empty list: $ helm ls NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION","title":"Introduction"},{"location":"introduction/#introduction","text":"TODO! document the attack vectors We\u2019ll start with possible attack vectors, to help you map out the threat model that applies to your cluster, so you can figure out where you need to focus your efforts for security. We\u2019ll show you how to compromise a deployment with a pod running with a known vulnerability. Once you\u2019ve had the attacker\u2019s eye-view, we\u2019ll walk you through the most important techniques and open source tools to prevent compromise. Scanning container images for vulnerabilities Configuring container images with security in mind, and checking them with policies Checking your Kubernetes configuration Enhancing security using GitOps","title":"Introduction"},{"location":"introduction/#create-a-kubernetes-cluster","text":"To follow along with the practical examples in this tutorial you'll need a Kubernetes cluster that you can experiment with. Since at times you will be deploying insecure code, please don't use your production cluster! You can run a cluster locally on your laptop, for example using Kind - Kubernetes IN Docker . We'll also be using Helm to run software on the Kind cluster.","title":"Create a Kubernetes cluster"},{"location":"introduction/#install-kind","text":"You can skip this step if you already have an up-to-date installation of kind . On MacOS using Homebrew: brew install kind On MacOS / Linux: curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.8.1/kind-$(uname)-amd64 chmod +x ./kind mv ./kind /some-dir-in-your-PATH/kind On Windows using Chocolatey: choco install kind For more details see the kind quickstart guide .","title":"Install kind"},{"location":"introduction/#create-the-kind-cluster","text":"kind create cluster Once it's up and running, check that you can see the node is up and running: kubectl get nodes This should show something like this: NAME STATUS ROLES AGE VERSION kind-control-plane Ready master 78m v1.18.2 Great! You have a Kubernetes cluster running locally that you can experiment with.","title":"Create the kind cluster"},{"location":"introduction/#install-helm","text":"If you don't already have Helm on your laptop, you'll want to install that too. Find full instructions in the Helm documentation or here is a quick guide: On MacOS using Homebrew: brew install helm On MacOS / Linux: curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 chmod +x get_helm.sh ./get_helm.sh On Windows using Chocolatey: choco install kubernetes-helm If you have a fresh Kind installation there won't be any Helm charts installed yet, so a helm ls will return an empty list: $ helm ls NAME NAMESPACE REVISION UPDATED STATUS CHART APP VERSION","title":"Install Helm"},{"location":"policies/","text":"Configuring pods to run securely \u00b6 Least privileges \u00b6 http://canihaznonprivilegedcontainers.info/ Network policies \u00b6 https://banzaicloud.com/blog/network-policy/ https://medium.com/@tufin/best-practices-for-kubernetes-network-policies-2b643c4b1aa OPA in action \u00b6 what is it mini example via https://play.openpolicyagent.org/ OPA Gatekeeper","title":"Policies"},{"location":"policies/#configuring-pods-to-run-securely","text":"","title":"Configuring pods to run securely"},{"location":"policies/#least-privileges","text":"http://canihaznonprivilegedcontainers.info/","title":"Least privileges"},{"location":"policies/#network-policies","text":"https://banzaicloud.com/blog/network-policy/ https://medium.com/@tufin/best-practices-for-kubernetes-network-policies-2b643c4b1aa","title":"Network policies"},{"location":"policies/#opa-in-action","text":"what is it mini example via https://play.openpolicyagent.org/ OPA Gatekeeper","title":"OPA in action"},{"location":"scanning/","text":"Vulnerability scanning \u00b6 The Shellshock vulnerability demonstrated is a serious vulnerability, but it's just one of thousands of known, exploitable vulnerabilities that range from negligible right up to critical in severity. To make sure that your container images don't include Including vulnerability scanning in your workflow \u00b6","title":"Scanning"},{"location":"scanning/#vulnerability-scanning","text":"The Shellshock vulnerability demonstrated is a serious vulnerability, but it's just one of thousands of known, exploitable vulnerabilities that range from negligible right up to critical in severity. To make sure that your container images don't include","title":"Vulnerability scanning"},{"location":"scanning/#including-vulnerability-scanning-in-your-workflow","text":"","title":"Including vulnerability scanning in your workflow"},{"location":"settings/","text":"Using secure Kubernetes settings \u00b6 When you install Kubernetes, there are numerous configuration settings that can affect security. In this section you'll learn about checking the settings in your cluster against the best practices advised by the Center for Internet Security. The CIS Benchmark \u00b6 TODO - add background link about CIS, the benchmarks and how it has tests for different components Running benchmark checks with kube-bench \u00b6 The open source tool kube-bench makes it easy to run the tests defined in the CIS Kubernetes benchmark. In this tutorial, you will use kube-bench to identify some insecure Kubernetes settings, and you'll remediate one of the settings to turn a failing test into a pass. You could run kube-bench in a cluster of your choice but for this tutorial we are showing it running in a kind (Kubernetes in Docker) single-node cluster that runs on your laptop as a Docker container. Run kube-bench on the kind cluster \u00b6 !!! What we are about to do is TERRIBLE practice but it makes it easier for us to write a platform-independent set of instructions for this tutorial. Never run YAML directly from the internet like this in your production cluster - check what's in it first! Create the kube-bench job \u00b6 kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/master/job.yaml You can watch the job until it has completed: kubectl get jobs --watch Hit Ctrl-C once the job has finished. Get the job output from the logs \u00b6 The job applies the label app: kube-bench to the pod, so you can easily retrieve the logs like this: kubectl logs $(kubectl get pods -l app=kube-bench -o name) Scroll back through the logs to see how it is divided into sections, each with its own set of results, remediation recommendations, and a summary. Most of the tests pass but there are a few results marked with [WARN] or [FAIL] [FAIL] means that the test failed [WARN] indicates that you need to do something manually to verify whether the test should pass or not. For more detail on the output check the kube-bench documentation . Remediate a test \u00b6 !!! This tutorial was written using Kubernetes 1.18.2 and testing against the CIS Kubernetes Benchmark v1.5.1. If you are using a later version of Kubernetes, it's possible that the default configuration settings have changed and the results you get might not match what is described here. Scroll back through the results to find the result and (further down the results) the remediation information for the test 4.2.6. ... [FAIL] 4.2.6 Ensure that the --protect-kernel-defaults argument is set to true (Scored) ... 4.2.6 If using a Kubelet config file, edit the file to set protectKernelDefaults: true. If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable. --protect-kernel-defaults=true Based on your system, restart the kubelet service. For example: systemctl daemon-reload systemctl restart kubelet.service Kind uses a kubelet configuration file that lives at /var/lib/kubelet/config.yaml , so only the first line of the remediation text applies - you don't have to worry about editing the kubelet service file or restarting the service. !!! When using kind, there is a Docker container running your control plane. This image for this container is based on Ubuntu so we can exec into the running container and then treat it much as if it were a virtual machine running a Kubernetes node. Edit the Kubelet configuration file \u00b6 First, open a shell into the kind container. docker exec -it kind-control-plane bash Assuming that it doesn't already have an editor installed, you can add one. apt-get update apt-get install vim Edit the Kubelet config file vi /var/lib/kubelet/config.yaml Add the line protectKernelDefaults: true so that the file looks something like this: apiVersion: kubelet.config.k8s.io/v1beta1 authentication: anonymous: enabled: false ... nodeStatusUpdateFrequency: 0s protectKernelDefaults: true rotateCertificates: true ... Save the file. The kubelet will spot that the configuration has changed and update itself, but meanwhile you can exit to leave the container so that you are back at your terminal where you can run kubectl commands on the kind cluster. Re-run kube-bench \u00b6 First delete the previous job: kubectl delete job kube-bench Run the kube-bench job, as before: kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/master/job.yaml Once the job has completed, get the test results from the logs kubectl logs $(kubectl get pods -l app=kube-bench -o name) This time you should see that test 4.2.6 passes. Congratulations, you have remediated a security setting on a Kubernetes node! !!! This only remediates the running node, of course! If you are managing your own Kubernetes nodes, it would be better to update the configuration settings you use in deployment scripts, so that the nodes are configured to run from the outset with the settings you want. Optional exercises \u00b6 If you download the job.yaml file used above, you can modify it to try some optional exercises. Run a specific test \u00b6 Sometimes you might want to run an individual test rather than the whole benchmark. For example, try to modify the command run in the job so that it only runs the test 4.2.6 that you remediated earlier. You can do this by specifying --check=4.2.6 as a parameter to the kube-bench command. Specify worker node tests only \u00b6 There are different CIS Kubernetes Benchmark tests for different node types in the cluster (master nodes, worker nodes, etcd nodes). On a managed Kubernetes system you might only have access to worker nodes, so you only need to run the tests that apply to those nodes. kube-bench tries to auto-detect which tests to run on any given node, but to keep things simple you may wish to specify worker node tests only. You might like to try out the job-node.yaml configuration which does just that.","title":"Secure settings"},{"location":"settings/#using-secure-kubernetes-settings","text":"When you install Kubernetes, there are numerous configuration settings that can affect security. In this section you'll learn about checking the settings in your cluster against the best practices advised by the Center for Internet Security.","title":"Using secure Kubernetes settings"},{"location":"settings/#the-cis-benchmark","text":"TODO - add background link about CIS, the benchmarks and how it has tests for different components","title":"The CIS Benchmark"},{"location":"settings/#running-benchmark-checks-with-kube-bench","text":"The open source tool kube-bench makes it easy to run the tests defined in the CIS Kubernetes benchmark. In this tutorial, you will use kube-bench to identify some insecure Kubernetes settings, and you'll remediate one of the settings to turn a failing test into a pass. You could run kube-bench in a cluster of your choice but for this tutorial we are showing it running in a kind (Kubernetes in Docker) single-node cluster that runs on your laptop as a Docker container.","title":"Running benchmark checks with kube-bench"},{"location":"settings/#run-kube-bench-on-the-kind-cluster","text":"!!! What we are about to do is TERRIBLE practice but it makes it easier for us to write a platform-independent set of instructions for this tutorial. Never run YAML directly from the internet like this in your production cluster - check what's in it first!","title":"Run kube-bench on the kind cluster"},{"location":"settings/#create-the-kube-bench-job","text":"kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/master/job.yaml You can watch the job until it has completed: kubectl get jobs --watch Hit Ctrl-C once the job has finished.","title":"Create the kube-bench job"},{"location":"settings/#get-the-job-output-from-the-logs","text":"The job applies the label app: kube-bench to the pod, so you can easily retrieve the logs like this: kubectl logs $(kubectl get pods -l app=kube-bench -o name) Scroll back through the logs to see how it is divided into sections, each with its own set of results, remediation recommendations, and a summary. Most of the tests pass but there are a few results marked with [WARN] or [FAIL] [FAIL] means that the test failed [WARN] indicates that you need to do something manually to verify whether the test should pass or not. For more detail on the output check the kube-bench documentation .","title":"Get the job output from the logs"},{"location":"settings/#remediate-a-test","text":"!!! This tutorial was written using Kubernetes 1.18.2 and testing against the CIS Kubernetes Benchmark v1.5.1. If you are using a later version of Kubernetes, it's possible that the default configuration settings have changed and the results you get might not match what is described here. Scroll back through the results to find the result and (further down the results) the remediation information for the test 4.2.6. ... [FAIL] 4.2.6 Ensure that the --protect-kernel-defaults argument is set to true (Scored) ... 4.2.6 If using a Kubelet config file, edit the file to set protectKernelDefaults: true. If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable. --protect-kernel-defaults=true Based on your system, restart the kubelet service. For example: systemctl daemon-reload systemctl restart kubelet.service Kind uses a kubelet configuration file that lives at /var/lib/kubelet/config.yaml , so only the first line of the remediation text applies - you don't have to worry about editing the kubelet service file or restarting the service. !!! When using kind, there is a Docker container running your control plane. This image for this container is based on Ubuntu so we can exec into the running container and then treat it much as if it were a virtual machine running a Kubernetes node.","title":"Remediate a test"},{"location":"settings/#edit-the-kubelet-configuration-file","text":"First, open a shell into the kind container. docker exec -it kind-control-plane bash Assuming that it doesn't already have an editor installed, you can add one. apt-get update apt-get install vim Edit the Kubelet config file vi /var/lib/kubelet/config.yaml Add the line protectKernelDefaults: true so that the file looks something like this: apiVersion: kubelet.config.k8s.io/v1beta1 authentication: anonymous: enabled: false ... nodeStatusUpdateFrequency: 0s protectKernelDefaults: true rotateCertificates: true ... Save the file. The kubelet will spot that the configuration has changed and update itself, but meanwhile you can exit to leave the container so that you are back at your terminal where you can run kubectl commands on the kind cluster.","title":"Edit the Kubelet configuration file"},{"location":"settings/#re-run-kube-bench","text":"First delete the previous job: kubectl delete job kube-bench Run the kube-bench job, as before: kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/master/job.yaml Once the job has completed, get the test results from the logs kubectl logs $(kubectl get pods -l app=kube-bench -o name) This time you should see that test 4.2.6 passes. Congratulations, you have remediated a security setting on a Kubernetes node! !!! This only remediates the running node, of course! If you are managing your own Kubernetes nodes, it would be better to update the configuration settings you use in deployment scripts, so that the nodes are configured to run from the outset with the settings you want.","title":"Re-run kube-bench"},{"location":"settings/#optional-exercises","text":"If you download the job.yaml file used above, you can modify it to try some optional exercises.","title":"Optional exercises"},{"location":"settings/#run-a-specific-test","text":"Sometimes you might want to run an individual test rather than the whole benchmark. For example, try to modify the command run in the job so that it only runs the test 4.2.6 that you remediated earlier. You can do this by specifying --check=4.2.6 as a parameter to the kube-bench command.","title":"Run a specific test"},{"location":"settings/#specify-worker-node-tests-only","text":"There are different CIS Kubernetes Benchmark tests for different node types in the cluster (master nodes, worker nodes, etcd nodes). On a managed Kubernetes system you might only have access to worker nodes, so you only need to run the tests that apply to those nodes. kube-bench tries to auto-detect which tests to run on any given node, but to keep things simple you may wish to specify worker node tests only. You might like to try out the job-node.yaml configuration which does just that.","title":"Specify worker node tests only"}]}