{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"This KubeCon EU 2020 tutorial will get you off the ground with Kubernetes security basics, using live demos and examples to work through yourself. We\u2019ll start with possible attack vectors, to help you map out the threat model that applies to your cluster, so you can figure out where you need to focus your efforts for security. We\u2019ll show you how to compromise a deployment with a pod running with a known vulnerability. Once you\u2019ve had the attacker\u2019s eye-view, we\u2019ll walk you through the most important techniques and open source tools to prevent compromise. Sign up now!","title":"Overview"},{"location":"gitops/","text":"GitOps \u00b6 Concept \u00b6 Using Flux \u00b6 Using ArgoCD \u00b6","title":"GitOps"},{"location":"gitops/#gitops","text":"","title":"GitOps"},{"location":"gitops/#concept","text":"","title":"Concept"},{"location":"gitops/#using-flux","text":"","title":"Using Flux"},{"location":"gitops/#using-argocd","text":"","title":"Using ArgoCD"},{"location":"introduction/","text":"Introduction \u00b6 TODO! We\u2019ll start with possible attack vectors, to help you map out the threat model that applies to your cluster, so you can figure out where you need to focus your efforts for security. We\u2019ll show you how to compromise a deployment with a pod running with a known vulnerability. Once you\u2019ve had the attacker\u2019s eye-view, we\u2019ll walk you through the most important techniques and open source tools to prevent compromise. Create a Kubernetes cluster \u00b6 To follow along with the practical examples in this tutorial you'll need a Kubernetes cluster that you can experiment with. Since at times you will be deploying insecure code, please don't use your production cluster! You can run a cluster locally on your laptop, for example using Kind - Kubernetes IN Docker . Install kind \u00b6 You can skip this step if you already have an up-to-date installation of kind . On MacOS using Homebrew: brew install kind On MacOS / Linux: curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.8.1/kind-$(uname)-amd64 chmod +x ./kind mv ./kind /some-dir-in-your-PATH/kind On Windows using Chocolatey: choco install kind For more details see the kind quickstart guide . Create the kind cluster \u00b6 kind create cluster Once it's up and running, check that you can see the node is up and running: kubectl get nodes This should show something like this: NAME STATUS ROLES AGE VERSION kind-control-plane Ready master 78m v1.18.2 Great! You have a Kubernetes cluster running locally that you can experiment with.","title":"Introduction"},{"location":"introduction/#introduction","text":"TODO! We\u2019ll start with possible attack vectors, to help you map out the threat model that applies to your cluster, so you can figure out where you need to focus your efforts for security. We\u2019ll show you how to compromise a deployment with a pod running with a known vulnerability. Once you\u2019ve had the attacker\u2019s eye-view, we\u2019ll walk you through the most important techniques and open source tools to prevent compromise.","title":"Introduction"},{"location":"introduction/#create-a-kubernetes-cluster","text":"To follow along with the practical examples in this tutorial you'll need a Kubernetes cluster that you can experiment with. Since at times you will be deploying insecure code, please don't use your production cluster! You can run a cluster locally on your laptop, for example using Kind - Kubernetes IN Docker .","title":"Create a Kubernetes cluster"},{"location":"introduction/#install-kind","text":"You can skip this step if you already have an up-to-date installation of kind . On MacOS using Homebrew: brew install kind On MacOS / Linux: curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.8.1/kind-$(uname)-amd64 chmod +x ./kind mv ./kind /some-dir-in-your-PATH/kind On Windows using Chocolatey: choco install kind For more details see the kind quickstart guide .","title":"Install kind"},{"location":"introduction/#create-the-kind-cluster","text":"kind create cluster Once it's up and running, check that you can see the node is up and running: kubectl get nodes This should show something like this: NAME STATUS ROLES AGE VERSION kind-control-plane Ready master 78m v1.18.2 Great! You have a Kubernetes cluster running locally that you can experiment with.","title":"Create the kind cluster"},{"location":"policies/","text":"Configuring pods to run securely \u00b6 Least privileges \u00b6 Network policies \u00b6 OPA in action \u00b6","title":"Policies"},{"location":"policies/#configuring-pods-to-run-securely","text":"","title":"Configuring pods to run securely"},{"location":"policies/#least-privileges","text":"","title":"Least privileges"},{"location":"policies/#network-policies","text":"","title":"Network policies"},{"location":"policies/#opa-in-action","text":"","title":"OPA in action"},{"location":"scanning/","text":"Including vulnerability scanning in your workflow \u00b6","title":"Scanning"},{"location":"scanning/#including-vulnerability-scanning-in-your-workflow","text":"","title":"Including vulnerability scanning in your workflow"},{"location":"settings/","text":"Using secure Kubernetes settings \u00b6 When you install Kubernetes, there are numerous configuration settings that can affect security. In this section you'll learn about checking the settings in your cluster against the best practices advised by the Center for Internet Security. The CIS Benchmark \u00b6 TODO - add background link about CIS, the benchmarks and how it has tests for different components Running benchmark checks with kube-bench \u00b6 The open source tool kube-bench makes it easy to run the tests defined in the CIS Kubernetes benchmark. In this tutorial, you will use kube-bench to identify some insecure Kubernetes settings, and you'll remediate one of the settings to turn a failing test into a pass. You could run kube-bench in a cluster of your choice but for this tutorial we are showing it running in a kind (Kubernetes in Docker) single-node cluster that runs on your laptop as a Docker container. Run kube-bench on the kind cluster \u00b6 !!! What we are about to do is TERRIBLE practice but it makes it easier for us to write a platform-independent set of instructions for this tutorial. Never run YAML directly from the internet like this in your production cluster - check what's in it first! Create the kube-bench job \u00b6 kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/master/job.yaml You can watch the job until it has completed: kubectl get jobs --watch Hit Ctrl-C once the job has finished. Get the job output from the logs \u00b6 The job applies the label app: kube-bench to the pod, so you can easily retrieve the logs like this: kubectl logs $(kubectl get pods -l app=kube-bench -o name) Scroll back through the logs to see how it is divided into sections, each with its own set of results, remediation recommendations, and a summary. Most of the tests pass but there are a few results marked with [WARN] or [FAIL] [FAIL] means that the test failed [WARN] indicates that you need to do something manually to verify whether the test should pass or not. For more detail on the output check the kube-bench documentation . Remediate a test \u00b6 !!! This tutorial was written using Kubernetes 1.18.2 and testing against the CIS Kubernetes Benchmark v1.5.1. If you are using a later version of Kubernetes, it's possible that the default configuration settings have changed and the results you get might not match what is described here. Scroll back through the results to find the result and (further down the results) the remediation information for the test 4.2.6. ... [FAIL] 4.2.6 Ensure that the --protect-kernel-defaults argument is set to true (Scored) ... 4.2.6 If using a Kubelet config file, edit the file to set protectKernelDefaults: true. If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable. --protect-kernel-defaults=true Based on your system, restart the kubelet service. For example: systemctl daemon-reload systemctl restart kubelet.service Kind uses a kubelet configuration file that lives at /var/lib/kubelet/config.yaml , so only the first line of the remediation text applies - you don't have to worry about editing the kubelet service file or restarting the service. !!! When using kind, there is a Docker container running your control plane. This image for this container is based on Ubuntu so we can exec into the running container and then treat it much as if it were a virtual machine running a Kubernetes node. Edit the Kubelet configuration file \u00b6 First, open a shell into the kind container. docker exec -it kind-control-plane bash Assuming that it doesn't already have an editor installed, you can add one. apt-get update apt-get install vim Edit the Kubelet config file vi /var/lib/kubelet/config.yaml Add the line protectKernelDefaults: true so that the file looks something like this: apiVersion: kubelet.config.k8s.io/v1beta1 authentication: anonymous: enabled: false ... nodeStatusUpdateFrequency: 0s protectKernelDefaults: true rotateCertificates: true ... Save the file. The kubelet will spot that the configuration has changed and update itself, but meanwhile you can exit to leave the container so that you are back at your terminal where you can run kubectl commands on the kind cluster. Re-run kube-bench \u00b6 First delete the previous job: kubectl delete job kube-bench Run the kube-bench job, as before: kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/master/job.yaml Once the job has completed, get the test results from the logs kubectl logs $(kubectl get pods -l app=kube-bench -o name) This time you should see that test 4.2.6 passes. Congratulations, you have remediated a security setting on a Kubernetes node! !!! This only remediates the running node, of course! If you are managing your own Kubernetes nodes, it would be better to update the configuration settings you use in deployment scripts, so that the nodes are configured to run from the outset with the settings you want. Optional exercises \u00b6 If you download the job.yaml file used above, you can modify it to try some optional exercises. Run a specific test \u00b6 Sometimes you might want to run an individual test rather than the whole benchmark. For example, try to modify the command run in the job so that it only runs the test 4.2.6 that you remediated earlier. You can do this by specifying --check=4.2.6 as a parameter to the kube-bench command. Specify worker node tests only \u00b6 There are different CIS Kubernetes Benchmark tests for different node types in the cluster (master nodes, worker nodes, etcd nodes). On a managed Kubernetes system you might only have access to worker nodes, so you only need to run the tests that apply to those nodes. kube-bench tries to auto-detect which tests to run on any given node, but to keep things simple you may wish to specify worker node tests only. You might like to try out the job-node.yaml configuration which does just that.","title":"Secure settings"},{"location":"settings/#using-secure-kubernetes-settings","text":"When you install Kubernetes, there are numerous configuration settings that can affect security. In this section you'll learn about checking the settings in your cluster against the best practices advised by the Center for Internet Security.","title":"Using secure Kubernetes settings"},{"location":"settings/#the-cis-benchmark","text":"TODO - add background link about CIS, the benchmarks and how it has tests for different components","title":"The CIS Benchmark"},{"location":"settings/#running-benchmark-checks-with-kube-bench","text":"The open source tool kube-bench makes it easy to run the tests defined in the CIS Kubernetes benchmark. In this tutorial, you will use kube-bench to identify some insecure Kubernetes settings, and you'll remediate one of the settings to turn a failing test into a pass. You could run kube-bench in a cluster of your choice but for this tutorial we are showing it running in a kind (Kubernetes in Docker) single-node cluster that runs on your laptop as a Docker container.","title":"Running benchmark checks with kube-bench"},{"location":"settings/#run-kube-bench-on-the-kind-cluster","text":"!!! What we are about to do is TERRIBLE practice but it makes it easier for us to write a platform-independent set of instructions for this tutorial. Never run YAML directly from the internet like this in your production cluster - check what's in it first!","title":"Run kube-bench on the kind cluster"},{"location":"settings/#create-the-kube-bench-job","text":"kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/master/job.yaml You can watch the job until it has completed: kubectl get jobs --watch Hit Ctrl-C once the job has finished.","title":"Create the kube-bench job"},{"location":"settings/#get-the-job-output-from-the-logs","text":"The job applies the label app: kube-bench to the pod, so you can easily retrieve the logs like this: kubectl logs $(kubectl get pods -l app=kube-bench -o name) Scroll back through the logs to see how it is divided into sections, each with its own set of results, remediation recommendations, and a summary. Most of the tests pass but there are a few results marked with [WARN] or [FAIL] [FAIL] means that the test failed [WARN] indicates that you need to do something manually to verify whether the test should pass or not. For more detail on the output check the kube-bench documentation .","title":"Get the job output from the logs"},{"location":"settings/#remediate-a-test","text":"!!! This tutorial was written using Kubernetes 1.18.2 and testing against the CIS Kubernetes Benchmark v1.5.1. If you are using a later version of Kubernetes, it's possible that the default configuration settings have changed and the results you get might not match what is described here. Scroll back through the results to find the result and (further down the results) the remediation information for the test 4.2.6. ... [FAIL] 4.2.6 Ensure that the --protect-kernel-defaults argument is set to true (Scored) ... 4.2.6 If using a Kubelet config file, edit the file to set protectKernelDefaults: true. If using command line arguments, edit the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubeadm.conf on each worker node and set the below parameter in KUBELET_SYSTEM_PODS_ARGS variable. --protect-kernel-defaults=true Based on your system, restart the kubelet service. For example: systemctl daemon-reload systemctl restart kubelet.service Kind uses a kubelet configuration file that lives at /var/lib/kubelet/config.yaml , so only the first line of the remediation text applies - you don't have to worry about editing the kubelet service file or restarting the service. !!! When using kind, there is a Docker container running your control plane. This image for this container is based on Ubuntu so we can exec into the running container and then treat it much as if it were a virtual machine running a Kubernetes node.","title":"Remediate a test"},{"location":"settings/#edit-the-kubelet-configuration-file","text":"First, open a shell into the kind container. docker exec -it kind-control-plane bash Assuming that it doesn't already have an editor installed, you can add one. apt-get update apt-get install vim Edit the Kubelet config file vi /var/lib/kubelet/config.yaml Add the line protectKernelDefaults: true so that the file looks something like this: apiVersion: kubelet.config.k8s.io/v1beta1 authentication: anonymous: enabled: false ... nodeStatusUpdateFrequency: 0s protectKernelDefaults: true rotateCertificates: true ... Save the file. The kubelet will spot that the configuration has changed and update itself, but meanwhile you can exit to leave the container so that you are back at your terminal where you can run kubectl commands on the kind cluster.","title":"Edit the Kubelet configuration file"},{"location":"settings/#re-run-kube-bench","text":"First delete the previous job: kubectl delete job kube-bench Run the kube-bench job, as before: kubectl apply -f https://raw.githubusercontent.com/aquasecurity/kube-bench/master/job.yaml Once the job has completed, get the test results from the logs kubectl logs $(kubectl get pods -l app=kube-bench -o name) This time you should see that test 4.2.6 passes. Congratulations, you have remediated a security setting on a Kubernetes node! !!! This only remediates the running node, of course! If you are managing your own Kubernetes nodes, it would be better to update the configuration settings you use in deployment scripts, so that the nodes are configured to run from the outset with the settings you want.","title":"Re-run kube-bench"},{"location":"settings/#optional-exercises","text":"If you download the job.yaml file used above, you can modify it to try some optional exercises.","title":"Optional exercises"},{"location":"settings/#run-a-specific-test","text":"Sometimes you might want to run an individual test rather than the whole benchmark. For example, try to modify the command run in the job so that it only runs the test 4.2.6 that you remediated earlier. You can do this by specifying --check=4.2.6 as a parameter to the kube-bench command.","title":"Run a specific test"},{"location":"settings/#specify-worker-node-tests-only","text":"There are different CIS Kubernetes Benchmark tests for different node types in the cluster (master nodes, worker nodes, etcd nodes). On a managed Kubernetes system you might only have access to worker nodes, so you only need to run the tests that apply to those nodes. kube-bench tries to auto-detect which tests to run on any given node, but to keep things simple you may wish to specify worker node tests only. You might like to try out the job-node.yaml configuration which does just that.","title":"Specify worker node tests only"}]}